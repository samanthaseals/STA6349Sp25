{
  "hash": "ae27e6cc147084e448c7d292759cf2f6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"**The Beta-Binomial Bayesian Model**\"\nsubtitle: \"**STA6349: Applied Bayesian Analysis** <br> Spring 2025\"\ndate-format: long\nexecute:\n  echo: true\n  warning: false\n  message: false\n  error: true\nformat: \n  revealjs:\n    code-overflow: wrap\n    embed-resources: true\n    slide-number: false\n    width: 1600\n    height: 900\n    html-math-method: katex\n    theme:\n      - default\n      - sp25.scss\neditor: source\n---\n\n\n\n## **Introduction** \n\n- Last week, we talked about creating posterior models for discrete priors (non-named distributions).\n\n- This week, we will now introduce having a named distribution as a prior.\n\n- We will start with analyzing a binomial outcome.\n\n    - Recall that the binomial distribution depends on $\\pi$.\n\n## **Example**\n\n- Consider the following scenario. \n    - \"Michelle\" has decided to run for president and you're her campaign manager for the state of Florida. \n    - As such, you've conducted 30 different polls throughout the election season. \n    - Though Michelle's support has hovered around 45%, she polled at around 35% in the dreariest days and around 55% in the best days on the campaign trail.\n    \n<center><img src=\"images/W07-L1-a.png\"></center>  \n\n## **Example**\n- Past polls provide prior information about $\\pi$, the proportion of Floridians that currently support Michelle. \n\n    - In fact, we can reorganize this information into a formal prior probability model of $\\pi$.\n\n- In a previous problem, we assumed that $\\pi$ could only be 0.2, 0.5, or 0.8, the corresponding chances of which were defined by a discrete probability model.\n\n    - However, in the reality of Michelle's election support, $\\pi \\in [0, 1]$. \n    \n- We can reflect this reality and conduct a Bayesian analysis by constructing a continuous prior probability model of $\\pi$.\n\n## **Example**\n\n<center><img src=\"images/W07-L1-a.png\"></center>  \n\n- A reasonable prior is represented by the curve on the right. \n\n    - Notice that this curve preserves the overall information and variability in the past polls, i.e., Michelle's support, $\\pi$ can be anywhere between 0 and 1, but is most likely around 0.45.\n\n## **Example**\n\n- Incorporating this more nuanced, continuous view of Michelle's support, $\\pi$, will require some new tools. \n    - No matter if our parameter $\\pi$ is continuous or discrete, the posterior model of $\\pi$ will combine insights from the prior and data. \n    - $\\pi$ isn’t the only variable of interest that lives on [0,1]. \n    \n- Maybe we're interested in modeling the proportion of people that use public transit, the proportion of trains that are delayed, the proportion of people that prefer cats to dogs, etc. \n    - The Beta-Binomial model provides the tools we need to study the proportion of interest, $\\pi$, in each of these settings.    \n    \n## **Beta Prior**\n\n<center><img src=\"images/W07-L1-a.png\"></center>  \n\n- In building the Bayesian election model of Michelle's election support among Floridians, $\\pi$, we begin with the prior. \n\n    - Our continuous prior probability model of $\\pi$ is specified by the probability density function (pdf). \n    \n- What values can $\\pi$ take and which are more plausible than others?\n\n## **Beta Prior**\n\n- Let $\\pi$ be a random variable, where $\\pi \\in [0, 1]$. \n\n- The variability in $\\pi$ may be captured by a Beta model with shape hyperparameters $\\alpha > 0$ and $\\beta > 0$,\n\n    - **hyperparameter:** a parameter used in a prior model.\n    \n$$ \\pi \\sim \\text{Beta}(\\alpha, \\beta), $$\n\n- Let's explore the shape of the Beta:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bayesrules)\nlibrary(tidyverse)\n\nplot_beta(1, 5) + theme_bw()\nplot_beta(1, 2) + theme_bw()\nplot_beta(3, 7) + theme_bw()\nplot_beta(1, 1) + theme_bw()\n```\n:::\n\n\n\n## **Beta Prior**\n\n<center>\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta(1, 5) + theme_bw() + ggtitle(\"Beta(1, 5)\")\n```\n\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n## **Beta Prior**\n\n<center>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta(1, 2) + theme_bw() + ggtitle(\"Beta(1, 2)\")\n```\n\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n## **Beta Prior**\n\n<center>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta(3, 7) + theme_bw() + ggtitle(\"Beta(3, 7)\")\n```\n\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n## **Beta Prior**\n\n<center>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta(1, 1) + theme_bw() + ggtitle(\"Beta(1, 1)\")\n```\n\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n## **Beta Prior**\n\n- Your turn!\n\n- Explore the following and report back:\n    - How would you describe the typical behavior of a Beta($\\alpha, \\beta$) variable, $\\pi$, when $\\alpha=\\beta$?\n    - How would you describe the typical behavior of a Beta($\\alpha, \\beta$) variable, $\\pi$, when $\\alpha>\\beta$?\n    - How would you describe the typical behavior of a Beta($\\alpha, \\beta$) variable, $\\pi$, when $\\alpha<\\beta$?\n    - For which model is there greater variability in the plausible values of $\\pi$, Beta(20, 20) or Beta(5, 5)?\n\n## **Tuning the Beta Prior**\n\n- We can *tune* the shape hyperparameters ($\\alpha$ and $\\beta$) to reflect our prior information about Michelle's election support, $\\pi$.\n\n- In our example, we saw that she polled between 25 and 65 percentage points, with an average of 45 percentage points.\n    - We want our Beta($\\alpha, \\beta$) to have similar patterns.\n    - We want to pick $\\alpha$ and $\\beta$ such that $\\pi$ is around 0.45.\n    \n$$\nE[\\pi] = \\frac{\\alpha}{\\alpha+\\beta} \\approx 0.45\n$$\n\n- Using algebra, we can tune, and find\n\n$$\\alpha \\approx \\frac{9}{11} \\beta$$\n\n## **Tuning the Beta Prior**\n\n- Your turn!\n\n    - Graph the following and determine which is best for the example.\n        \n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta(9, 11) + theme_bw()\nplot_beta(27, 33) + theme_bw()\nplot_beta(45, 55) + theme_bw()\n```\n:::\n\n\n        \n- Recall, this is what we are going for:        \n\n<center><img src=\"images/W07-L1-a.png\"></center>  \n\n## **Tuning the Beta Prior**\n\n<center>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta(9, 11) + theme_bw() + ggtitle(\"Beta(9, 11)\")\n```\n\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n## **Tuning the Beta Prior**\n\n<center>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta(27, 33) + theme_bw() + ggtitle(\"Beta(27, 33)\")\n```\n\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n## **Tuning the Beta Prior**\n\n<center>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta(45, 55) + theme_bw() + ggtitle(\"Beta(45, 55)\")\n```\n\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n## **Tuning the Beta Prior**\n\n- Now that we have a prior, we \"know\" some things.\n\n$$\\pi \\sim \\text{Beta}(45, 55)$$\n\n- From the properties of the beta distribution,\n\n$$\n\\begin{equation*}\n\\begin{aligned}\nE[\\pi] &= \\frac{\\alpha}{\\alpha + \\beta} & \\text{ and } & \\text{ } & \\text{ }  \\\\\n&=\\frac{45}{45+55} \\\\\n&= 0.45\n\\end{aligned} \n\\begin{aligned}\n\\text{var}[\\pi] &= \\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)} \\\\\n&= \\frac{(45)(55)}{(45+55)^2(45+55+1)} \\\\\n&= 0.0025\n\\end{aligned}\n\\end{equation*}\n$$\n\n\n## **The Binomial Data Model and Likelihood Function**\n        \n- Now we are ready to think about the data collection.\n\n- A new poll of $n = 50$ Floridians recorded $Y$, the number that support Michelle. \n\n    - The results depend upon $\\pi$ -- the greater Michelle’s actual support, the greater $Y$ will tend to be. \n    \n- To model the dependence of $Y$ on $\\pi$, we assume\n\n    - voters answer the poll independently of one another;\n    - the probability that any polled voter supports your candidate Michelle is $\\pi$\n    \n- This is a binomial event, $Y|\\pi \\sim \\text{Bin}(50, \\pi)$,  with conditional pmf, $f(y|\\pi)$ defined for $y \\in \\{0, 1, ..., 50\\}$\n\n$$f(y|\\pi) = P[Y = y|\\pi] = {50 \\choose y} \\pi^y (1-\\pi)^{50-y}$$\n\n## **The Binomial Data Model and Likelihood Function**\n\n- The conditional pmf, $f(y|\\pi)$, gives us answers to a hypothetical question:\n\n    - If Michelle's support were given some value of $\\pi$, then how many of the 50 polled voters ($Y=y$) might we expect to suppport her?\n\n- Let's look at this graphically:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 50\npi <- value of pi\n\nbinom_prob <- tibble(n_success = 1:n,\n                     prob = dbinom(n_success, size=n, prob=pi))\n\nbinom_prob %>%\n  ggplot(aes(x=n_success,y=prob))+\n  geom_col(width=0.2)+\n  labs(x= \"Number of Successes\",\n       y= \"Probability\") +\n  theme_bw()\n```\n:::\n\n\n\n## **The Binomial Data Model and Likelihood Function**\n\n\n\n::: {.cell}\n\n:::\n\n\n\n<center>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n\n## **The Binomial Data Model and Likelihood Function**\n\n<center>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n\n## **The Binomial Data Model and Likelihood Function**\n\n<center>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n## **The Binomial Data Model and Likelihood Function**\n\n- It is observed that $Y=30$ of the $n=50$ polled voters support Michelle.\n\n- We now want to find the likelihood function -- remember that we treat $Y=30$ as the observed data and $\\pi$ as unknown,\n\n$$\n\\begin{align*}\nf(y|\\pi) &= {50 \\choose y} \\pi^y (1-\\pi)^{50-y} \\\\\nL(\\pi|y=30) &= {50 \\choose 30} \\pi^{30} (1-\\pi)^{20}\n\\end{align*}\n$$\n\n- This is valid for $\\pi \\in [0, 1]$.\n\n## **The Binomial Data Model and Likelihood Function**\n\n- What is the likelihood of 30/50 voters supporting Michelle?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(30, 50, pi)\n```\n:::\n\n\n\n- You try this for $\\pi = \\{0.25, 0.50, 0.75\\}$.\n\n## **The Binomial Data Model and Likelihood Function**\n\n- What is the likelihood of 30/50 voters supporting Michelle?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(30, 50, pi)\n```\n:::\n\n\n\n- For $\\pi = 0.25$,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(30, 50, 0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.29633e-07\n```\n\n\n:::\n:::\n\n\n\n- For $\\pi = 0.5$,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(30, 50, 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.04185915\n```\n\n\n:::\n:::\n\n\n\n- For $\\pi = 0.75$,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(30, 50, 0.75)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.007654701\n```\n\n\n:::\n:::\n\n\n\n## **The Binomial Data Model and Likelihood Function**\n\n- Challenge!\n\n- Create a graph showing what happens to the likelihood for different values of $\\pi$.\n\n    - i.e., have $\\pi$ on the $x$-axis and likelihood on the $y$-axis.\n    \n- To get you started,    \n    \n\n\n::: {.cell}\n\n```{.r .cell-code}\ngraph <- tibble(pi = seq(0, 1, 0.001)) %>%\n  mutate(likelihood = dbinom(30, 50, pi))\n```\n:::\n\n\n    \n## **The Binomial Data Model and Likelihood Function**\n\n- Create a graph showing what happens to the likelihood for different values of $\\pi$.\n\n<center>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n- Where is the maximum?\n\n## **The Binomial Data Model and Likelihood Function**\n\n- Where is the maximum?\n\n<center>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-23-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n## **The Beta Posterior Model**\n\n$$\n\\begin{align*}\nY|\\pi &\\sim \\text{Bin}(50, \\pi) \\\\\n\\pi &\\sim \\text{Beta}(45, 55)\n\\end{align*}\n$$\n\n<center>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-24-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n- The prior is a bit more pessimistic about Michelle's election support than the data obtained from the latest poll.\n\n## **The Beta Posterior Model**\n\n- Let's graph the posterior,\n\n<center>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50) + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-25-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n- We can see that the posterior model of $\\pi$ is continuous and $\\in [0, 1]$.\n\n- The shape of the posterior appears to also have a Beta($\\alpha$, $\\beta$) model.\n\n    - The shape parameters ($\\alpha$ and $\\beta$) have been *updated*.\n\n## **The Beta Posterior Model**\n    \n- If we were to collect more information about Michelle's support, we would use the current posterior as the new prior, then update our posterior. \n\n    - How do we know what the updated parameters are?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      model alpha beta mean      mode         var         sd\n1     prior    45   55 0.45 0.4489796 0.002450495 0.04950248\n2 posterior    75   75 0.50 0.5000000 0.001655629 0.04068942\n```\n\n\n:::\n:::\n\n\n\n## **The Beta-Binomial Model**\n\n- We used Michelle's election support to understand the Beta-Binomial model.\n\n- Let's now generalize it for any appropriate situation.\n\n$$\n\\begin{align*}\nY|\\pi &\\sim \\text{Bin}(n, \\pi) \\\\\n\\pi &\\sim \\text{Beta}(\\alpha, \\beta) \\\\\n\\pi | (Y=y) &\\sim \\text{Beta}(\\alpha+y, \\beta+n-y)\n\\end{align*}\n$$\n\n- We can see that the posterior distribution reveals the influence of the prior ($\\alpha$ and $\\beta$) and data ($y$ and $n$).\n\n## **The Beta-Binomial Model**\n\n- Under this updated distribution,\n\n$$\n\\pi | (Y=y) \\sim \\text{Beta}(\\alpha+y, \\beta+n-y)\n$$\n\n- we have updated moments:\n\n$$\n\\begin{align*}\nE[\\pi | Y = y] &= \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\n\\text{Var}[\\pi|Y=y] &= \\frac{(\\alpha+y)(\\beta+n-y)}{(\\alpha+\\beta+n)^2(\\alpha+\\beta+1)}\n\\end{align*}\n$$\n\n## **The Beta-Binomial Model**\n\n- Let's pause and think about this from a theoretical standpoint.\n\n- The Beta distribution is a *conjugate prior* for the likelihood.\n\n    - **Conjugate prior**: the posterior is from the same model family as the prior.\n    \n- Recall the Beta prior, $f(\\pi)$, \n\n$$ L(\\pi|y) = {n \\choose y} \\pi^y (1-\\pi)^{n-y} $$\n\n- and the likelihood function, $L(\\pi|y)$.\n\n$$ f(\\pi) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\pi^{\\alpha-1}(1-\\alpha)^{\\beta-1} $$\n\n## **The Beta-Binomial Model**\n\n- We can put the prior and likelihood together to create the posterior,\n\n$$\n\\begin{align*}\nf(\\pi|y) &\\propto f(\\pi)L(\\pi|y) \\\\\n&= \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\pi^{\\alpha-1}(1-\\pi)^{\\beta-1} \\times {n \\choose y} \\pi^y (1-\\pi)^{n-1} \\\\\n&\\propto \\pi^{(\\alpha+y)-1} (1-\\pi)^{(\\beta+n-y)-1}\n\\end{align*}\n$$\n\n- This is the same structure as the normalized Beta($\\alpha+y, \\beta+n-y$),\n\n$$f(\\pi|y) = \\frac{\\Gamma(\\alpha+\\beta+n)}{\\Gamma(\\alpha+y) \\Gamma(\\beta+n-y)} \\pi^{(\\alpha+y)-1} (1-\\pi)^{(\\beta+n-y)-1}$$\n\n## **Example**\n\n- In a 1963 issue of The Journal of Abnormal and Social Psychology, Stanley Milgram described a study in which he investigated the propensity of people to obey orders from authority figures, even when those orders may harm other people ([Milgram 1963](https://psycnet.apa.org/record/1964-03472-001?doi=1)).\n\n- Study participants were given the task of testing another participant (who was a trained actor) on their ability to memorize facts. \n\n- If the actor didn't remember a fact, the participant was ordered to administer a shock on the actor and to increase the shock level with every subsequent failure. \n\n- Unbeknownst to the participant, the shocks were fake and the actor was only pretending to register pain from the shock.\n\n## **Example**\n\n- The parameter of interest here is $\\pi$, the chance that a person would obey authority (in this case, administering the most severe shock), even if it meant bringing harm to others. \n    - Since Milgram passed away in 1984, we don’t have the opportunity to ask him about his understanding of $\\pi$ prior to conducting the study.\n    - Suppose another psychologist helped carry out this work. Prior to collecting data, they indicated that a Beta(1,10) model accurately reflected their understanding about $\\pi$.\n\n- The outcome of interest is $Y$, the number of the $n=40$ study participants that would inflict the most severe shock. \n\n- What model is appropriate?\n\n## **Example**\n\n- What model is appropriate?\n\n- Assuming that each participant behaves independently of the others, we can model the dependence of $Y$ on $\\pi$ using the Binomial.\n\n- Thus, we have a Beta-Binomial Bayesian model.\n\n$$\n\\begin{align*}\nY|\\pi &\\sim \\text{Bin}(40, \\pi) \\\\\n\\pi &\\sim \\text{Beta}(1, 10)\n\\end{align*}\n$$\n\n## **Example**\n\n- What do you think this prior reveals about the psychologist's prior understanding of $\\pi$?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta(alpha = 1, beta = 10)\n```\n:::\n\n\n\na. They don't have an informed opinion.\n\nb. They're fairly certain that a large proportion of people will do what authority tells them.\n\nc. They're fairly certain that only a small proportion of people will do what authority tells them.\n\n## **Example**\n\n- What do you think this prior reveals about the psychologist's prior understanding of $\\pi$?\n\n<center>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-28-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n**c. They're fairly certain that only a small proportion of people will do what authority tells them.**\n\n## **Example**\n\n- After data collection, $Y = 26$ of the $n=40$ study participants inflected what they understood to be the maximum shock. \n\n- From the problem set up,\n\n$$\n\\begin{align*}\nY|\\pi &\\sim \\text{Bin}(40, \\pi) \\\\\n\\pi &\\sim \\text{Beta}(1, 10)\n\\end{align*}\n$$\n\n- Use what you know to find the posterior model of $\\pi$,\n\n$$\\pi|(Y=26) \\sim \\text{Beta}(\\text{??}, \\text{??})$$\n\n## **Example**\n\n- After data collection, $Y = 26$ of the $n=40$ study participants inflected what they understood to be the maximum shock. \n\n- Use what you know to find the posterior model of $\\pi$,\n\n$$\\pi|(Y=26) \\sim \\text{Beta}(\\text{??}, \\text{??})$$\n\n- With $\\alpha = 1$ and $\\beta = 10$, we know the posterior distribution will be as follows,\n\n$$\n\\begin{align*}\n\\pi | (Y=y) &\\sim \\text{Beta}(\\alpha+y, \\beta+n-y) \\\\\n&\\sim \\text{Beta}(1+26, 10+40-26) \\\\\n&\\sim \\text{Beta}(27, 24)\n\\end{align*}\n$$\n\n## **Example**\n\n- Let's find the summary,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_beta_binomial(alpha = 1, beta = 10, y = 26, n = 40)\n```\n:::\n\n\n\n- and graph the distributions involved,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta_binomial(alpha = 1, beta = 10, y = 26, n = 40)\n```\n:::\n\n\n\n- What belief did we have for $\\pi$ before considering the data?\n\n- What belief do we have for $\\pi$ after considering the prior and the observed data?\n\n## **Example**\n\n- Let's find the summary,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_beta_binomial(alpha = 1, beta = 10, y = 26, n = 40)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      model alpha beta       mean      mode         var         sd\n1     prior     1   10 0.09090909 0.0000000 0.006887052 0.08298827\n2 posterior    27   24 0.52941176 0.5306122 0.004791057 0.06921746\n```\n\n\n:::\n:::\n\n\n\n- and graph the distributions involved,\n\n<center>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_beta_binomial(alpha = 1, beta = 10, y = 26, n = 40) + theme_bw()\n```\n\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-32-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n## **Example** \n\n<center>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](W08-L1-beta-binomial_files/figure-revealjs/unnamed-chunk-33-1.png){width=576}\n:::\n:::\n\n\n</center>\n\n- What belief did we have for $\\pi$ before considering the data?\n\n    - Fewer than 25% of people would inflict the most severe shock.\n\n- What belief do we have for $\\pi$ after considering the prior and the observed data?\n\n    - Somewhere between 30% and 70% of people would inflict the most severe shock.\n\n## **Wrap Up**\n\n- Today we have built the Beta-Binomial model for $\\pi$, an unknown proportion.\n\n$$\n\\begin{equation*}\n\\begin{aligned}\nY|\\pi &\\sim \\text{Bin}(n,\\pi) \\\\\n\\pi &\\sim \\text{Beta}(\\alpha,\\beta) &\n\\end{aligned} \n\\Rightarrow \n\\begin{aligned}\n&& \\pi | (Y=y) &\\sim \\text{Beta}(\\alpha+y, \\beta+n-y) \\\\\n\\end{aligned}\n\\end{equation*}\n$$\n\n- The prior model, $f(\\pi)$, is given by Beta($\\alpha,\\beta$).\n\n- The data model, $f(Y|\\pi)$, is given by Bin($n,\\pi$).\n\n- The likelihood function, $L(\\pi|y)$, is obtained by plugging $y$ into the Binomial pmf.\n\n- The posterior model is a Beta distribution with updated parameters $\\alpha+y$ and $\\beta+n-y$.\n\n## **Homework** \n\n- 3.3\n- 3.9\n- 3.10\n- 3.18\n\n",
    "supporting": [
      "W08-L1-beta-binomial_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}